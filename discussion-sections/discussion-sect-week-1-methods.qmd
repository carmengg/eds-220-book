
# Discussion Section

October 5, 2023.

This discussion section will guide you through preliminary data exploration for a real world dataset about animal observations in the California drylands. Our goals are:

- Keep practicing setting up a GitHub repository and git commit/ git push.
- Collaborate with your new team!
- Practice getting preliminary information from a dataset from its archive
- Introduce `pd.read_csv()` for loading files directly from an URL
- Introduce preliminary exploration strategies in `pandas`

:::{.callout-tip}
## Notebook Setup
1. Create a new repository on GitHub. Use the following settings:

    a. Call the repository `eds-220-section-1`.

    b. Add a brief description for your new repository. For example: EDS 220 section - practice session for data selection in pandas.

    c. Keep the repository public.

    d. Initialize the repository with a `README` file and a Python .gitignore template.

2. Clone the repository to a new directory in the Taylor server under your `eds-220` directory.

3. In the terminal use `cd` to navigate into the `eds-220-section-1` directory. Use `pwd` to verify `eds-220-section-1` is your current working directory.

3. Create a new Python Notebook in `eds-220-section-1`. 

4. Update the notebook's name to something useful like 'exercise-data-selection.qmd'.

5. Use the terminal to stage, commit, and push this file to the remote repository. Remember:
    - stage: `git add FILE_NAME`
    - commit with message: `git commit -m "COMMIT_MESSAGE"`
    - push: `git push`

6. If you are prompted for your credentials and need to set up a new Personal Access Token (PAT) follow [steps 13-18 in this guide](https://docs.google.com/document/d/1Pk6_rUDdFjdGg-YVo9Cl8ET3iDsYahyaP0VMRD4UHUk/edit?usp=sharing/) to set it up.


<p style="text-align: center;">
**CHECK IN WITH YOUR TEAM** 
</p>
<p style="text-align: center;">
**MAKE SURE YOU'VE ALL SUCCESSFULLY SET UP YOUR NOTEBOOKS BEFORE CONTINUING**
</p>

:::


:::{.callout-note}
## General directions
- Add comments in each one of your code cells 
- Include markdown cells in between your code cells to add titles/information to each exercise
- Check the git status and commit/push after each exercise. 
- You don't need to write anything in the notebook about exercises 1 and 2. 
:::

:::{.callout-note}
## About the data

For this exercise we will use data about [prey items for endangered terrestrial vertebrate species within central California drylands (King et. al, 2023)](https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1VM49RH). 

This dataset is stored in the [Knowledge Network for Biocomplexity (KNB)](https://knb.ecoinformatics.org) data repository. This is an international repository intended to facilitate ecological and environmental research. It has thousands of open datasets and is hosted by NCEAS!
:::

<!-- Data exploration -->
## Archive exploration
For many datasets, data exploration begins at the data repository. Take some time to look through the dataset's description in KNB. Discuss the following questions with your team:

a. Does this dataset come with an associated metadata file?
b. Is this data collected in-situ by the authors or is it a synthesis of multiple datasets?
c. Does the dataset contain sensitive data?
d. During what time frame were the observations in the dataset collected?

## `.xml` metadata exploration

You may have noticed there are two metadata files: `Compiled_occurrence_records_for_prey_items_of.xml` and `metadata_arth_occurrences.csv`. 

a. In the archive's dataset description, notice the `.xml` document file type is `EML` which stands for [EML: Ecological Metadata Language](https://eml.ecoinformatics.org). 
b. Open the `.xml` file: there's a lot going on. This is a machine-readable file that has metadata about *the whole dataset*. You can proably identify some items like title and creators. 
c. Close the file and delete it - we won't use it today. 

## `.csv` metadata exploration

Back in your notebook, import the `pandas` package using standard abbreviation in a code cell. Then follow these steps to read in the metadata csv using the `pandas.read_csv()` function:

a. Navigate to the [data package site](https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1VM49RH) and copy the URL to access the `arth_occurrences_with_env` csv file. To copy the URL: 

- hover over the Download button –> right click –> “Copy Link".

b. Read in the data from the URL using the `pd.read_csv()` function like this:

    ```python
    # read in data
    pd.read_csv('the URL goes here')
    ```

c. Take a minute to look at the descriptions for the columns. 

**Note:** Not all datasets have column descriptions in a `csv` file. Often they come with a `doc` or `txt` file with information. 

<!-- Data loading -->
## Data loading
a. Follow steps (a) and (b) from the previous exercise to read in the drylands prey data file `arth_occurrences_with_env.csv` using `pd.read_csv()`. Store the dataframe to a variable called `prey` like this:

```python
# read in data
prey = pd.read_csv('the URL goes here')
```

b. Use a Python function to see what is the type of the `prey` variable. 

<p style="text-align: center;">
**CHECK IN WITH YOUR TEAM** 
</p>
<p style="text-align: center;">
**MAKE SURE YOU'VE ALL SUCCESSFULLY ACCESSED THE DATA BEFORE CONTINUING**
</p>

## Look at your data

a. Run `prey` in a cell. What do you notice in the columns section?

b. To see all the column names in the same display we need to set a `pandas` option. Run the following command and then look at the `prey` data again:
```python
pd.set_option("display.max.columns", None)
```

## `pd.DataFrame` preliminary exploration

Run each of the following methods for `prey` in a different cell and write a brief description of what they do as a comment: 

a. `head()`
b. `tail()`
c. `info()`
d. `nunique()`

For example:

```
# head()
# returns the first five rows of the data frame
prey.head()
```

If you're not sure about what the method does, try looking it up in the [`pandas.DataFrame` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).

e. Check the [documentation for `head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head). If this function has any default parameters, change them to get a different output. 

Print each of the following attributes of `prey` in a different cell and write a brief explanation of what they do as a comment:

f. `shape`
g. `columns`
h. `dtypes`

If you're not sure about what info is the attribute showing, try looking it up in the [`pandas.DataFrame` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).

## For fun
Change the column names of `institutionCode` and `datasetKey` to `institution_code` and  `dataset_key`, respectively. HINT: yesterday's class.

# References

Rachel King, Jenna Braun, Michael Westphal, & CJ Lortie. (2023). Compiled occurrence records for prey items of listed species found in California drylands with associated environmental data. Knowledge Network for Biocomplexity. doi:10.5063/F1VM49RH.

Lortie, C. J., Braun, J., King, R., & Westphal, M. (2023). The importance of open data describing prey item species lists for endangered species. Ecological Solutions and Evidence, 4(2), e12251. https://doi.org/10.1002/2688-8319.12251


<!--
```{python}
import pandas as pd
pd.read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A3baf7289-bf90-4db3-ad11-58785c09b26e")
```


```{python}
prey = pd.read_csv("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A23d42528-1048-45d4-85d1-7e13b666e744")
prey
```
-->