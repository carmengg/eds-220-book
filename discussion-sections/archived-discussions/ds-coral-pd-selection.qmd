# Discussion Section 1

Date: October 6, 2023.
<!--
## Exercise 1
Consider the following code:


```{python}
import numpy as np

?np.ones
```
![](/images/lesson-1/np-ones-docstring.png)

```{python}
arr = np.ones([3,2], dtype=np.int8)
print(arr)

x = arr.mean()
print(x)
```

Complete the following paragraph using the given words:

| . | . | .| .|
|---|---|---|---|
| class | function | object |method |
| variable | non-default |data-type |default |
|package | attribute | outout | parameter(s) | optional|

`arr` is a ________ assigned to the ________ `np.ones([3,2])`. We construct `np.ones([3,2])` by calling a ________ from the NumPy ________. `[3,2]` and `np.int8` are ________ we pass to the `np.ones` ________. `np.int8` is a ________ parameter of `np.ones`. `mean` is a ________ of `abc` and `x` is its ________. 
-->

:::{.callout-tip}
## Notebook Setup
1. Create a new repository on GitHub. Use the following settings:

    a. Call the repository `eds-220-section-1`.

    b. Add a brief description for your new repository. For example: EDS 220 section - practice session for data selection in pandas.

    c. Keep the repository public.

    d. Initialize the repository with a `README` file and a Python .gitignore template.

2. Clone the repository to a new directory in the Taylor server under your `eds-220` directory.

3. In the terminal use `cd` to navigate into the `eds-220-section-1` directory. Use `pwd` to verify `eds-220-section-1` is your current working directory.

3. Create a new Python Notebook in `eds-220-section-1`. 

4. Update the notebook's name to something useful like 'exercise-data-selection.qmd'.

5. Use the terminal to stage, commit, and push this file to the remote repository. Remember:
    - stage: `git add FILE_NAME`
    - commit with message: `git commit -m "COMMIT_MESSAGE"`
    - push: `git push`

6. If you are prompted for your credentials and need to set up a new Personal Access Token (PAT) follow [steps 13-18 in this guide](https://docs.google.com/document/d/1Pk6_rUDdFjdGg-YVo9Cl8ET3iDsYahyaP0VMRD4UHUk/edit?usp=sharing/) to set it up.
:::


:::{.callout-note}
## General directions
Add comments in each one of your code cells and include markdown cells to add titles to the different execises. 
:::

:::{.callout-note}
## About the data

For this exercise we are going to use data about  [Western Indian Ocean Coral Diversity (McClanahan, 2023)](https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1K35S3H).

This dataset is stored in the [Knowledge Network for Biocomplexity (KNB)](https://knb.ecoinformatics.org) data repository. This is an international repository intended to facilitate ecological and environmental research. It has thousands of open datasets and is hosted by NCEAS!

 Navigate to dataset's link and briefly explore the data package.
:::

<!-- Data loading -->
**1.** Import the pandas package using standard abbreviation in a code cell. Then follow these steps to read in the csv file in the Western Indian Ocean Coral Diversity data using the `pandas.read_csv()` function:

a. Navigate to the [data package site](https://knb.ecoinformatics.org/view/doi%3A10.5063%2FF1K35S3H) and copy the the URL to access the `WesternIndianOceanCoralDiversity` csv file. To copy the URL: 

- hover over the Download button –> right click –> “Copy Link".

b. Read in the data from the URL using the `pd.read_csv` function and store it as `coral_div` like this:

    ```python
    # read in data
    coral_div = pd.read_csv('the URL goes here')
    ```


:::{.callout-tip collapse="true"}
## Solution
```{python}
# import pandas library
import pandas as pd

# load data directly from data archive
coral_div = pd.read_csv('https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3Ae7d12a5a-f1a9-4a3e-aaa5-5222f67e799d')
```
:::

<!-- Basic data frame information -->
**2.** Use attributes and methods of the `coral_div` data frame to obtain the following information about it:

a. how many rows and columns does it have?
b. see the first 5 rows
c. what are the column names?
d. what are the data types of the columns?

In this last step, what is the difference between the `int64` and `float64` data types?

:::{.callout-tip collapse="true"}
## Solution
```{python}
# check the shape of dataframe: (# rows, # columns)
coral_div.shape
``` 

```{python}
# see the first five rows of dataframe
coral_div.head()
```

```{python}
# obtain the column names as an array
coral_div.columns
```

```{python}
# check the data type of each column
coral_div.dtypes
```
:::

<!-- Understand syntax of column selection -->
**3.** The `Country` column indicates the country of reef location. Explain in your words what is the ouput of `coral_div.Country` and `coral_div.Country.unique()`. 

:::{.callout-tip collapse="true"}
## Solution
`coral_div.Country` returns the `Country` column of the dataframe, this is a `pandas.Series`. 

`coral_div.Country.unique()` returns the unique values of the `Country` column. These are the countries where the reefs are located:

```{python}
# countries where reefs are located
coral_div.Country.unique()
```
:::

<!-- Check metadata + select column + unique + len -->
**4.** Check the dataset's [metadata file README_md.doc](https://knb.ecoinformatics.org/view/doi:10.5063/F1K35S3H) to find which column has information about who made an observation. How many observers collected this data? HINT: use the `len` Python function. Not sure what `len` does? Use `?`.

:::{.callout-tip collapse="true"}
## Solution
```{python}
# nunber of observers in the dataset
len(coral_div.Observer.unique())
```

:::

<!-- Understand syntax for row selection using condition -->
**5.** The `Coralcover` column indicates the percent of hard coral cover in each 6km reef cell surveyed. What data is `coral_div[coral_div['Coralcover'] >= 50]` selecting?

:::{.callout-tip collapse="true"}
## Solution
We are selecting the rows where the coral cover was at least 50 percent. 
:::

<!-- Use multiple conditions for row selection -->
**6.** Are there any sites with a 30% coral cover in Tanzania?

:::{.callout-tip collapse="true"}
## Solution
We can check this by using two conditions to select rows. The first condition is `coral_div['Coralcover']==30` and the second is `coral_div.Country == 'Tanzania'`. We use the `&` and operator to look for rows that satisfy both condtions:
```{python}
# remember to add parenthesis around each condition
# check if ther are any sites with a 30% coral cover in Tanzania
coral_div[(coral_div['Coralcover']==30) & (coral_div.Country == 'Tanzania')]
```
:::

<!-- Select columns using a list -->
**7.** We are interested in looking at the PH of sea water (`PH` column),  mean salinity (PSS) (`Salinity_mean` column), and depth of survey location in meters (`Depth` column). Select this data. 

:::{.callout-tip collapse="true"}
## Solution

```{python}
# select columns using a list with their names
coral_div[['PH','Salinity_mean','Depth']]
```
:::

<!-- Select rows and columns simultaneously using loc -->
**8.** The `max_yr` column indicates the year of last sampling at a given site. Select the PH, salinity, and depth for sites where sampling ended in 2017. 

:::{.callout-tip collapse="true"}
## Solution
```{python}
# use loc to select rows and columns simultaneously by label or conditions
coral_div.loc[coral_div.max_yr == 2017 ,['PH','Salinity_mean','Depth']]
```
:::

<!-- Select data using iloc-->
**9.** Use `iloc` to select rows 95 throuhg 100 (including 100) in the 17th, 20th, and 28th columns and assign these values to a new variable called `subset`. HINT: the ouput columns should be `Salinity_mean`, `mean.npp` and `Current_vel_mean`. Are you indexing from 0?

:::{.callout-tip collapse="true"}
## Solution
```{python}
# use iloc to subset data by location
subset = coral_div.iloc[ 95:101 , [16,19,27] ]
```
:::

<!-- Understand what isna method does -->
**10.** Run `subset.isna()`. Explain what this code does and what the output represents.

:::{.callout-tip collapse="true"}
## Solution
We are using the method `isna()` of the dataframe `susbset`. We can see the ouput is a dataframe of the same shape as `subset` indicating wheter an entry is an `NA` or not. 

```{python}
subset.isna()
```
:::

<!-- Understand method concatenation -->
**11.** Run `subset.isna().any()`. Explain what this code does and what the output represents. HINT: It could be helpful to check the [documentation of `pandas.Sries.any`](https://pandas.pydata.org/docs/reference/api/pandas.Series.any.html).

:::{.callout-tip collapse="true"}
## Solution
Adding `.any()` to `susbet.isna()` tells us which column have `NA` values in them. If the output is `False` then there are no `NA` values, if the output is `True`, then there are `NA`s in the column.

```{python}
subset.isna().any()
```
:::

<!-- Row subset using method for masking column -->
**12.** Select the rows in `subset` that have NA in the `Current_vel_mean` column. HINT: you can use your answer for 9.

:::{.callout-tip collapse="true"}
## Solution
```{python}
# another example of selecting rows using a condition
subset[subset['Current_vel_mean'].isna()]
```
:::
    

## References
Tim McClanahan. (2023). Western Indian Ocean Coral Diversity. Knowledge Network for Biocomplexity. doi:10.5063/F1K35S3H.

<!-- https://stackoverflow.com/questions/36226083/how-to-find-which-columns-contain-any-nan-value-in-pandas-dataframe -->
