<!-- 
Fixing the preview working directory
```{python}
import os
home = os.path.expanduser("~")
os.chdir(os.path.join(home,'eds-220-book'))
```

Ignore ShapelyDeprecationWarning warning in render

```{python}
import shapely
import warnings
from shapely.errors import ShapelyDeprecationWarning

warnings.filterwarnings("ignore", category=ShapelyDeprecationWarning) 
```
-->

# Merging data

In this section we will learn how to join dataframes and will apply this to creating a choropleth map with `geopandas`.

## Types of Joins

Frequently, analysis of data will require merging these separately managed tables back together. There are multiple ways to join the observations in two tables, based on how the rows of one table are merged with the rows of the other. Regardless of the join we will perform, we need to start by identifying the primary key in each table and how these appear as foreign keys in other tables.

When conceptualizing merges, one can think of two tables, one on the *left* and one on the *right*.

![](/images/merging_data/join-diagrams-separate.png)

### Inner Join
An *INNER JOIN*  is when you merge the subset of rows that have matches in both the left table and the right table.

![](/images/merging_data/join-diagrams-inner.png)

### Left Join
A *LEFT JOIN* takes all of the rows from the left table, and merges on the data from matching rows in the right table. Keys that don't match from the left table are still provided with a missing value (na) from the right table. 

![](/images/merging_data/join-diagrams-left.png)

### Right Join
A *RIGHT JOIN* is the same as a left join, except that all of the rows from the right table are included with matching data from the left, or a missing value. Notice that left and right joins can ultimately be the same depending on the positions of the tables

![](/images/merging_data/join-diagrams-right.png)


### Full Outer Join
Finally, a *FULL OUTER JOIN* includes all data from all rows in both tables, and includes missing values wherever necessary.

![](/images/merging_data/join-diagrams-full.png)

Sometimes people represent joins as Venn diagrams, showing which parts of the left and right tables are included in the results for each join. This representation is useful, however, they miss part of the story related to where the missing value comes from in each result.

![Image source: R for Data Science, Wickham & Grolemund.](/images/merging_data/join-venn.png)

We suggest reading<a href=https://r4ds.had.co.nz/relational-data.html#join-problems target="_blank"> the Relational Data chapter in the "R for Data Science" book </a> for more examples and best practices about joins.

## Goal
Our goal in this lesson will be to join two datasets, one with demographic information and another with country outlines, to create the following choropleth map showing the number of Arctic communities by country and their location in [Scandinavia](https://en.wikipedia.org/wiki/Scandinavia):

![](/images/arctic-comms.png)

## Data

We will use two datasets in this lesson. 
 The first dataset is [Natural Earth's medium scale  cultural boundaries data (1:50m)](https://www.naturalearthdata.com/downloads/50m-cultural-vectors/). 
We can obtain this dataset by downloading the shapefile. 
[Natural Earth](https://www.naturalearthdata.com) is a public domain dataset with ready-to-use data for creating maps. 

The second dataset we will use is a [list of Arctic communities and their location (Brook, 2023)](https://search.dataone.org/view/doi%3A10.18739%2FA28S4JQ80) which can be accessed through the DataONE repository. 
This is a GeoJSON file with the following attributes:

- **name**: name of Arctic community, 
- **population**: population of Arctic community, as of 2022
- **country**: country that the Arctic community falls within (see dataset metadata for the codes)
- **geoname-id**: numeric codes that uniquely identify all administrative/legal and statistical geographic areas for which the Census Bureau tabulates data


## Data preparation

We start our analysis by importing the necessary libraries:

```{python}
import pandas as pd
import matplotlib.pyplot as plt

import geopandas as gpd
```

<!--
# will use this library to add a background to our map
import contextily as ctx
-->

The Natural Earth dataset has many columns, so we need to update the `pandas` display settings to show all columns:

```{python}
# display all column when looking at dataframes
pd.set_option("display.max.columns", None)
```

### Countries 

Now we move on to preparing the polygons for the Scandinavian countries.
To import the Natural Earth countries polygons we use the `geopandas.read_file()` function again:

```{python}
# import countries polygons
countries = gpd.read_file('data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp')
countries.head()
```

Taking a quick look at this dataset:

```{python}
# quick view
countries.plot()
```

Notice the column names are in all caps. 
It is easier to work with column names in small caps because we don't need to be pressing shift or capslock. 
We can do this update like this:

```{python}
# re-assign the column names: .str.lower() makes them lower case
countries.columns = countries.columns.str.lower()
print(countries.columns)
```

Next, we want to select only the data for Scandinavian countries (Aland Islands, Denmark, Finland, Faroe Islands, Iceland, Norway, and Sweden) and a few of the 169 columns in the dataset:

```{python}
# names of Scandinavian countries
scandi_names = ['Aland Islands',
                'Denmark',
                'Finland',
                'Faroe Islands',
                'Iceland',
                'Norway',
                'Sweden']

# select Scandi countries and admin, type, and geometry columns
# remeber: the geometry column has the polygons for each country
scandi_countries = countries.loc[countries.admin.isin(scandi_names),['admin','type','geometry']]
scandi_countries
```

Notice the Aland Islands do not appear in the `scandi_countries` dataframe. 
Let's verify that the 'Aland Islands' value does not occur anywhere in the dataframe:

```{python}
# check Aland Islands is nowhere in data frame
'Aland Islands' in countries.values
```

The `values` attribute of a dataframe returns all the values in the dataframe as an array:

```{python}
# the underlying values of the dataframe
countries.values
```

### Arctic communities

In the same way as we previously used `pandas.read_csv()`, we can read in the Arctic communities data directly from the data repository using `geopandas.read_file()`:

```{python}
# read in Arctic communities data
communities = gpd.read_file('https://cn.dataone.org/cn/v2/resolve/urn%3Auuid%3Aed7718ae-fb0d-43dd-9270-fbfe80bfc7a4')
communities.head()
```


Notice that the `countries` and `communities` GeoDataFrames both have the same crs:

```{python}
countries.crs == communities.crs
```

This makes it easy to take a quick look at our communities data by plotting it on top of the countries dataframe:

```{python}
fig, ax = plt.subplots()
countries.plot(ax=ax)
communities.plot(ax=ax, color='red')
plt.show()
```

Next, we want to calculate the number of arctic communities by country. 

```{python}
# calculate number of communities by country

# extract number of communities by country as a pd.Series
n_comms = communities.groupby('country').count().name

# convert the pd.Series into a pd.DataFrame and update it
n_comms = pd.DataFrame(n_comms).rename(columns={'name':'n_communities'}).reset_index()
```

Let's break this down a bit:

- We start with our `communities` dataframe and use `groupby('country')` to group by country code, 
- then we use `count()` as an aggregator function to count how many rows belong to each country code.
- The result of this operation is a dataframe (run `communities.groupby('country').count()` to check) and we select a single column with the counts by selecting the `name` column.
- The result is a single `pd.Series` in the variable `n_comms`.
- We then convert this `pd.Series` into a `pd.DataFrame` and clean it up a bit.

```{python}
# number of communities per country
n_comms
```

 Since we only want data from Scandinavia, we can use the codes for these countries to locate these rows:

```{python}
# select Scandinavia data
scandi_codes = ['DK','NO','SE','FO','FI','IS','AX']
scandi_n_comms = n_comms[n_comms.country.isin(scandi_codes)].copy()
scandi_n_comms
```

## Merge datasets 

To merge two datasets they need to have at least one column in common. 
Currently our datasets do not have any columns in common:

```{python}
scandi_countries.head(2)
```

```{python}
scandi_n_comms.head(2)
```

We can easily fix this by adding an `admin` column to `scandi_n_comms`. 
Conveniently, the `scandi_names` list is in the same order as the country codes in the `scandi_n_comms` dataframe, so we can readily add this list as a new column:

```{python}
# Add country names 
scandi_n_comms['admin'] = scandi_names
scandi_n_comms
```

```{python}
scandi_countries = pd.merge(scandi_countries,scandi_n_comms)
scandi_countries
```

## Choropleth map

A [choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) is an efficient way to visualize aggregate data per region. 

To make a choropleth map from our polygons `GeoDataFrame` we need to specify the `column` parameter in `plot()` and make it equal to the column with the values we want to plot in each country. 

```{python}
scandi_countries.plot(column='n_communities',
                      legend=True)
```

To finish, we can use `matplotlib` to customize our map:

```{python}
fig, ax = plt.subplots(figsize=(10, 10))

scandi_countries.plot(ax=ax,
                      column='n_communities',
                       cmap='BuPu',
                       legend=True,
                       edgecolor='black',
                       legend_kwds={'shrink':.8,
                                    'label': 'Number of Arctic communities', 
                                    'orientation': 'horizontal'
                                    }
                       )


ax.set_title('Arctic communities in Scandinavia',  fontsize=20)
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')

plt.show()
```

<!--
# use ctx to add a basemap     
# ctx.add_basemap(ax=ax, 
#                attribution=False,
#                crs=scandi_countries.crs.to_string())
-->

<!--
EXERCISES:

Add the scandinavian communities as dots on the choropleth map.

-->

<!--
## Complete workflow

```python
# import libraries
import pandas as pd
import matplotlib.pyplot as plt

import geopandas as gpd

# ======= IMPORT DATA ========
# read in Arctic communities data
communities = gpd.read_file('https://cn.dataone.org/cn/v2/resolve/urn%3Auuid%3Aed7718ae-fb0d-43dd-9270-fbfe80bfc7a4')

# import countries polygons
countries = gpd.read_file('ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp')
countries.head()

# ======= COMMUNITIES PREPARATION =======
# extract number of communities by country as a pd.Series
n_comms = communities.groupby('country').count().name

# convert the pd.Series into a pd.DataFrame and update it
n_comms = pd.DataFrame(n_comms).rename(columns={'name':'n_communities'}).reset_index()

# select Scandinavia data
scandi_codes = ['DK','NO','SE','FO','FI','IS','AX']
scandi_n_comms = n_comms[n_comms.country.isin(scandi_codes)].copy()

# ======= COUNTRIES PREPARATION =======
# make column names lower case
countries.columns = countries.columns.str.lower()

# names of Scandinavian countries
scandi_names = ['Aland Islands',
                'Denmark',
                'Finland',
                'Faroe Islands',
                'Iceland',
                'Norway',
                'Sweden']

# subset Scandinavian countries
scandi_countries = countries.loc[countries.admin.isin(scandi_names),['admin','type','geometry']]

# ======= MERGE DATASETS =======
scandi_n_comms['admin'] = scandi_names
scandi_countries = pd.merge(scandi_countries, scandi_n_comms)

```
-->

## Acknowledgments

The section about merging data is based on the [Data Modeling Essentials R lesson](https://learning.nceas.ucsb.edu/2023-06-delta/session_09.html#merging-data) from the NCEAS Learning Hub. 

## References

Halina Do-Linh, Carmen Galaz García, Matthew B. Jones, Camila Vargas Poulsen. 2023. Open Science Synthesis training Week 1. NCEAS Learning Hub & Delta Stewardship Council.

Mike Brook. (2023). Approximate Arctic Communities and Populations, (latitude >= 55, 2022). Arctic Data Center. doi:10.18739/A28S4JQ80.