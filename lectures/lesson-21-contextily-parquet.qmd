---
jupyter: mpc-env-kernel
---
# Misc

In this lesson we will retrieve data from the [2020 Census from the Microsoft Planetary Computer's STAC catalog](https://planetarycomputer.microsoft.com/dataset/us-census) using **GeoParquet**. 
We will also introduce the **contextily** library for adding basemaps. 


## Parquet and GeoParquet

[**Apache Parquet**](https://parquet.apache.org) (or just parquet) is an open-source, column-oriented file format that makes it faster to retrieve data and uses less memory space to store tabular data. It is very popular for storing large amounts of data, instead of using, for example, CSV files. 


<!-- https://towardsdatascience.com/demystifying-the-parquet-file-format-13adb0206705

https://www.upsolver.com/blog/apache-parquet-why-use
-->

The geospatial version of parquet for storing vector data is the [**GeoParquet**](https://geoparquet.org) data format. 
This format comes from the necessity to have an efficient, standardized data format to store and query big geospatial data efficiently. 
GeoParquet was first introduced in December 2022. 
Similarly to STAC, this is a new and ongoing effort to create standards in the geospatial analysis community given the rapid increase in geospatial data available. 

<!-- https://getindata.com/blog/introducing-geoparquet-data-format/ 

https://cholmes.medium.com/geoparquet-1-0-0-beta-1-released-6390ecb4c6d0

https://geoparquet.org
-->


## Catalog search

We start by importing all the necessary libraries:

```{python}
import geopandas as gpd
import matplotlib.pyplot as plt

# for MPC's STAC catalog search
import pystac_client
import planetary_computer

import contextily as ctx #for adding basemaps
```

<!--
References:

Tile gallery:
https://xyzservices.readthedocs.io/en/stable/gallery.html

Intro to contextily
https://contextily.readthedocs.io/en/latest/intro_guide.html#

Geopandas:
https://geopandas.org/en/stable/gallery/plotting_basemap_background.html#add-background-tiles-to-plot

Troubleshooting:
https://github.com/geopandas/contextily/issues/118
https://github.com/geopandas/contextily/issues/78
-->

Then we use the 2020 US Census Collection id, `'us-census'`, to look for the data in the MPC catalog. 
This collection has each tabular file as an item:

```{python}
# open MPC catalog
catalog = pystac_client.Client.open(
    "https://planetarycomputer.microsoft.com/api/stac/v1",
    modifier=planetary_computer.sign_inplace,
)

# search whole collection
search = catalog.search(collections=["us-census"])

# retrieve items
items = {item.id: item for item in search.items()}
list(items)
```

This time we will access the item with the counties data:

```{python}
item = items['2020-cb_2020_us_county_500k']
item
```

Notice each item has a single asset, `'data'`, that contains an URL to the GeoParquet file holding the information. 
Let's access the item's asset:

```{python}
asset = item.assets["data"]
asset
```

## Opening (Geo)Parquet

To open the parquet file we use the `gpd.read_parquet()` function using the asset's URL pointing to the data. 

```{python}
counties = gpd.read_parquet(
    asset.href,
    # 
    storage_options=asset.extra_fields["table:storage_options"],
)
```

Now we have a regular `geopandas.GeoDataFrame`:

```{python}
print(type(counties))
counties.head()
```

## Contextily

In this section we will introduce the Python library [**contextily**](https://contextily.readthedocs.io/en/latest/index.html) to add base maps. 

Contextily retrieves tile maps from the internet and makes it possible to plot them alongside our vector data. 

**Example**

We want to plot the Santa Barbara county polygon together with a basemap. 

```{python}
sb = counties[df.NAME == "Santa Barbara"]
```

Although contextily's tiles can be reprojected to match the CRS of the vector data, it can be easier to reproject your data to EPSG 3857 instead. 
The [CRS EPSG 3857](https://epsg.io/3857) (Spherical Mercator / Web Mercator) is a projected coordinate system used for rendering maps online, including Google Maps and OpenStreetMap among others. 

```{python}
# create axis with plot
ax = (sb.to_crs(epsg=3857)
      .plot(figsize=(7, 7), alpha=0.5, edgecolor="k")
      )

# add basemap from contextily
ctx.add_basemap(ax)

# update axes
ax.set_title("Santa Barbara County", fontdict={"fontsize": "20"})
ax.set_axis_off()
```

By default, `contextily` uses the [OpenStreetMap HOT style](http://map.hotosm.org/). 
We can change basemaps by updating the `source` parameter in the `add_basemap()` function. For example:

```{python}
# create axis with plot
ax = (sb.to_crs(epsg=3857)
      .plot(figsize=(7, 7), alpha=0.5, edgecolor="k")
      )

# add NatGeo basemap from contextily
ctx.add_basemap(ax, source=ctx.providers.Esri.NatGeoWorldMap)

# update axes
ax.set_title("Santa Barbara County", fontdict={"fontsize": "20"})
ax.set_axis_off()
```

Checking `ctx.providers` we can see the basemaps available:

```{python}
ctx.providers
```


<!--
https://contextily.readthedocs.io/en/latest/providers_deepdive.html

```{python}
# # there's no phoenix subdivision in 2020 census data
# cousub = items['2020-cb_2020_us_cousub_500k']
# cousub_df = geopandas.read_parquet(
#     asset.href,
#     storage_options=asset.extra_fields["table:storage_options"],
# )
# cousub_df[cousub_df['NAME']=='Phoenix']
```
-->

## Acknowledgements

This lesson was adapted from teh MPC's notebook [Accessing US Census data with the Planetary Compyter STAC API](https://planetarycomputer.microsoft.com/dataset/us-census#Example-Notebook).